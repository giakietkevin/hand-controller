import streamlit as st
from streamlit_webrtc import webrtc_streamer, WebRtcMode, RTCConfiguration
import cv2
import numpy as np

# --- ÄOáº N ÄÃƒ Sá»¬A: XÃ³a chá»¯ 'engine.' Ä‘i ---
from hand_tracking import HandDetector
from controller import HandController
# -----------------------------------------

# Cáº¥u hÃ¬nh STUN Server (Äá»ƒ camera cháº¡y qua internet)
RTC_CONFIGURATION = RTCConfiguration(
    {"iceServers": [{"urls": ["stun:stun.l.google.com:19302"]}]}
)

st.set_page_config(page_title="Hand Controller", layout="centered")
st.title("ğŸ® AI Virtual Mouse")

# Khá»Ÿi táº¡o model má»™t láº§n duy nháº¥t vÃ o Session State
if 'detector' not in st.session_state:
    st.session_state.detector = HandDetector(model_complexity=0)
    st.session_state.controller = HandController()

def video_frame_callback(frame):
    # Chuyá»ƒn Ä‘á»•i frame tá»« WebRTC sang Ä‘á»‹nh dáº¡ng OpenCV
    img = frame.to_ndarray(format="bgr24")
    img = cv2.flip(img, 1) # Láº­t áº£nh nhÆ° soi gÆ°Æ¡ng
    
    # 1. TÃ¬m bÃ n tay
    img, landmarks = st.session_state.detector.findHands(img)
    
    # 2. Xá»­ lÃ½ logic Ä‘iá»u khiá»ƒn
    if landmarks:
        gesture = st.session_state.controller.get_gesture(landmarks)
        index_tip = landmarks[8] # Äáº§u ngÃ³n trá»
        
        # Äá»•i mÃ u dá»±a trÃªn hÃ nh Ä‘á»™ng
        color = (0, 255, 0) if gesture == "CLICK" else (0, 0, 255)
        
        # Váº½ con trá» áº£o
        cv2.circle(img, (int(index_tip[0]), int(index_tip[1])), 15, color, cv2.FILLED)
        cv2.putText(img, f"Status: {gesture}", (20, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, color, 2)

    return img

# Cháº¡y luá»“ng video
webrtc_streamer(
    key="hand-controller",
    mode=WebRtcMode.SENDRECV,
    rtc_configuration=RTC_CONFIGURATION,
    video_frame_callback=video_frame_callback,
    media_stream_constraints={"video": True, "audio": False},
    async_processing=True,
)